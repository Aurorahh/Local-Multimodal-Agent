import streamlit as st
import os
import time
from PIL import Image
from tqdm import tqdm

try:
    from src.vision_expert import VisionExpert
    from src.db_manager import DBManager
    from src.llm_client import LLMClient
    from src.file_handler import extract_text_from_pdf, move_file_to_category
except ImportError as e:
    st.error(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    st.stop()

# ==========================================
# 1. é¡µé¢é…ç½® & çŠ¶æ€åˆå§‹åŒ–
# ==========================================
st.set_page_config(
    page_title="Local Multimodal Agent",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ä½¿ç”¨ Session State ç¼“å­˜æ¨¡å‹å’Œæ•°æ®ï¼Œé¿å…åˆ·æ–°ä¸¢å¤±
if 'agent_loaded' not in st.session_state:
    st.session_state.agent_loaded = False
if 'img_description' not in st.session_state:
    st.session_state.img_description = None

# ==========================================
# 2. ä¾§è¾¹æ ï¼šç³»ç»Ÿåˆå§‹åŒ–
# ==========================================
st.sidebar.title("ğŸ¤– æ§åˆ¶å°")

# æ¨¡å‹åŠ è½½å‡½æ•°
@st.cache_resource
def load_models():
    print("â³ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
    vision = VisionExpert()
    db = DBManager()
    llm = LLMClient()
    return vision, db, llm

# åŠ è½½æ¨¡å‹
with st.sidebar:
    st.write("ç³»ç»ŸçŠ¶æ€æ£€æµ‹...")
    try:
        vision_expert, db_manager, llm_client = load_models()
        st.success("âœ… å…¨ç³»ç»Ÿæ¨¡å‹å·²å°±ç»ª")
        st.session_state.agent_loaded = True
        
        st.divider()
        st.info(f"ğŸ“‚ çŸ¥è¯†åº“è·¯å¾„: {os.path.abspath('./data/chroma_db')}")
        st.info(f"ğŸ–¼ï¸ è§†è§‰æ¨¡å‹: Florence-2-Large")
        st.info(f"ğŸ§  æ¨ç†æ¨¡å‹: Qwen-2.5") 
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        st.stop()

# ==========================================
# 3. ä¸»ç•Œé¢é€»è¾‘
# ==========================================
st.title("ğŸ§  æœ¬åœ°å¤šæ¨¡æ€æ™ºèƒ½ä½“ (Local Agent)")
st.markdown("æ”¯æŒ **æ‰¹é‡æ–‡çŒ®æ•´ç†** | **è¯­ä¹‰æ£€ç´¢** | **è§†è§‰ç†è§£**")

# åˆ›å»ºä¸¤ä¸ªä¸»è¦çš„åŠŸèƒ½é€‰é¡¹å¡
tab_knowledge, tab_vision = st.tabs(["ğŸ“š çŸ¥è¯†åº“ä¸“å®¶ (Knowledge)", "ğŸ‘ï¸ è§†è§‰ä¸“å®¶ (Vision)"])

# --- TAB 1: çŸ¥è¯†åº“åŠŸèƒ½ ---
with tab_knowledge:
    st.header("ğŸ“š æ™ºèƒ½æ–‡çŒ®ç®¡ç†")
    
    # å­åŠŸèƒ½é€‰æ‹©
    k_mode = st.radio("é€‰æ‹©æ“ä½œ:", ["æ‰¹é‡å…¥åº“ä¸åˆ†ç±» (Batch Process)", "è¯­ä¹‰æ£€ç´¢ (RAG Search)"], horizontal=True)
    
    if k_mode == "æ‰¹é‡å…¥åº“ä¸åˆ†ç±» (Batch Process)":
        st.markdown("#### ğŸ“‚ æ‰¹é‡æ–‡æ¡£å¤„ç†")
        st.info("è¯¥åŠŸèƒ½å°†æ‰«ææŒ‡å®šæ–‡ä»¶å¤¹ï¼Œè‡ªåŠ¨è¯†åˆ«è®ºæ–‡ä¸»é¢˜ï¼Œå¹¶å°†å…¶**ç§»åŠ¨**åˆ°åˆ†ç±»å­æ–‡ä»¶å¤¹ä¸­ã€‚")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            # é»˜è®¤æŒ‡å‘ä½ çš„ ./paper ç›®å½•
            target_dir = st.text_input("è¾“å…¥è®ºæ–‡æ‰€åœ¨æ–‡ä»¶å¤¹è·¯å¾„:", value="./paper")
            topics_str = st.text_input("è®¾ç½®åˆ†ç±»æ ‡ç­¾ (ç”¨é€—å·åˆ†éš”):", value="Computer Vision, NLP, Reinforcement Learning, Robotics")
        
        with col2:
            st.write("##") # å ä½
            start_btn = st.button("ğŸš€ å¼€å§‹æ‰¹é‡æ•´ç†", type="primary", use_container_width=True)
        
        if start_btn:
            if not os.path.exists(target_dir):
                st.error(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {target_dir}")
            else:
                # === æ ¸å¿ƒæ‰¹é‡å¤„ç†é€»è¾‘ ===
                st.write(f"ğŸ” æ­£åœ¨æ‰«æ `{target_dir}` ...")
                
                # æ”¶é›† PDF
                pdf_files = [os.path.join(target_dir, f) for f in os.listdir(target_dir) if f.lower().endswith('.pdf')]
                
                if not pdf_files:
                    st.warning("âš ï¸ è¯¥ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° PDF æ–‡ä»¶ã€‚")
                else:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    log_area = st.container() # ç”¨äºæ˜¾ç¤ºæ—¥å¿—
                    
                    processed_count = 0
                    
                    for i, file_path in enumerate(pdf_files):
                        filename = os.path.basename(file_path)
                        status_text.text(f"æ­£åœ¨å¤„ç†: {filename} ...")
                        
                        try:
                            # 1. æå–æ–‡æœ¬
                            chunks = extract_text_from_pdf(file_path)
                            if not chunks:
                                continue
                                
                            # 2. LLM åˆ†ç±»
                            first_page = chunks[0]['text']
                            category = llm_client.classify_paper(first_page, topics_str)
                            
                            # 3. ç§»åŠ¨æ–‡ä»¶
                            new_path = move_file_to_category(file_path, category)
                            
                            # 4. å­˜å…¥å‘é‡åº“
                            db_manager.add_paper_chunks(new_path, chunks, category)
                            
                            # 5. UI åé¦ˆ
                            with log_area:
                                st.success(f"âœ… {filename} -> ğŸ“‚ **{category}** (å·²å…¥åº“)")
                            
                            processed_count += 1
                        except Exception as e:
                            st.error(f"å¤„ç† {filename} å¤±è´¥: {e}")
                        
                        # æ›´æ–°è¿›åº¦æ¡
                        progress_bar.progress((i + 1) / len(pdf_files))
                    
                    status_text.text("ğŸ‰ å¤„ç†å®Œæˆï¼")
                    st.balloons()

    elif k_mode == "è¯­ä¹‰æ£€ç´¢ (RAG Search)":
        st.markdown("#### ğŸ§  çŸ¥è¯†åº“é—®ç­”")
        query = st.text_input("è¯·è¾“å…¥å­¦æœ¯é—®é¢˜:", placeholder="ä¾‹å¦‚: Transformer çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ")
        
        if st.button("ğŸ” æœç´¢å¹¶å›ç­”"):
            if query:
                with st.spinner("æ­£åœ¨æ£€ç´¢å‘é‡æ•°æ®åº“å¹¶ç”Ÿæˆå›ç­”..."):
                    # 1. æ£€ç´¢
                    results = db_manager.search_papers(query, n_results=3)
                    
                    if not results['ids'][0]:
                        st.warning("ğŸ“­ çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚")
                    else:
                        # 2. æ„å»ºä¸Šä¸‹æ–‡
                        context_str = ""
                        st.markdown("### ğŸ“„ å‚è€ƒæ¥æº")
                        for i in range(len(results['ids'][0])):
                            meta = results['metadatas'][0][i]
                            text = results['documents'][0][i]
                            score = 1 - results['distances'][0][i]
                            
                            with st.expander(f"æ¥æº {i+1}: {os.path.basename(meta['source'])} (Page {meta['page']}) - ç›¸å…³åº¦ {score:.2f}"):
                                st.write(text)
                                st.caption(f"åˆ†ç±»: {meta['category']}")
                            
                            context_str += f"æ–‡æ¡£: {meta['source']} (Page {meta['page']})\nå†…å®¹: {text}\n\n"
                        
                        # 3. LLM å›ç­”
                        st.markdown("### ğŸ¤– AI å›ç­”")
                        answer = llm_client.chat_with_context(query, context_str)
                        st.write(answer)

# --- TAB 2: è§†è§‰åŠŸèƒ½ (æ ¸å¿ƒä¿®æ”¹åŒºåŸŸ) ---
with tab_vision:
    st.header("ğŸ‘ï¸ è§†è§‰æ„ŸçŸ¥")
    v_mode = st.radio("åŠŸèƒ½:", ["å›¾ç‰‡æè¿° & é—®ç­” (Caption & VQA)", "ä»¥æ–‡æœå›¾ (Image Search)"], horizontal=True)
    
    if v_mode == "å›¾ç‰‡æè¿° & é—®ç­” (Caption & VQA)":
        col_img, col_desc = st.columns([1, 1])
        
        with col_img:
            uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["jpg", "png", "webp", "jpeg"])
            if uploaded_file:
                image = Image.open(uploaded_file)
                st.image(image, caption="é¢„è§ˆ", use_container_width=True)
                
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶ä¾›æ¨¡å‹è¯»å–è·¯å¾„
                temp_path = f"temp_{uploaded_file.name}"
                image.save(temp_path)
                
                # æ¢å›¾ç‰‡æ—¶æ¸…ç©ºç¼“å­˜
                if 'last_img' not in st.session_state or st.session_state.last_img != uploaded_file.name:
                    st.session_state.img_description = None
                    st.session_state.last_img = uploaded_file.name
        
        with col_desc:
            if uploaded_file:
                # 1. æ·±åº¦æè¿°æ¨¡å—
                st.markdown("#### 1. æ·±åº¦æè¿°")
                if st.button("ğŸ“ ç”Ÿæˆæè¿°"):
                    with st.spinner("Florence-2 æ­£åœ¨è§‚å¯Ÿå›¾ç‰‡ç»†èŠ‚..."):
                        # ä½¿ç”¨ MORE_DETAILED_CAPTION ç”Ÿæˆæœ€è¯¦ç»†çš„æ–‡æœ¬
                        res = vision_expert.analyze_image(temp_path, prompt_type="<MORE_DETAILED_CAPTION>")
                        st.session_state.img_description = res # å­˜å…¥ç¼“å­˜
                        st.success("åˆ†æå®Œæˆ")
                        st.info(res)
                
                st.divider()
                
                # 2. è§†è§‰é—®ç­”æ¨¡å— (Visual RAG)
                st.markdown("#### 2. è§†è§‰é—®ç­” (Visual RAG)")
                st.caption("ğŸš€ å‡çº§ç‰ˆ: ç»“åˆ Florence-2 çš„è§†è§‰èƒ½åŠ›ä¸ LLM çš„æ¨ç†èƒ½åŠ›ï¼Œæ”¯æŒä¸­æ–‡ï¼")
                
                user_q = st.text_input("é—®å›¾ç‰‡ä¸€ä¸ªé—®é¢˜:", placeholder="è¿™åªç¾Šæ˜¯ä»€ä¹ˆé¢œè‰²çš„ï¼Ÿ/ What is this?")
                
                if st.button("â“ æé—®"):
                    # 1. ç¡®ä¿æœ‰å…¨å±€æè¿°
                    if not st.session_state.img_description:
                        with st.spinner("ğŸ‘€ AI æ­£åœ¨é˜…è¯»å›¾ç‰‡å…¨å±€å†…å®¹..."):
                            st.session_state.img_description = vision_expert.analyze_image(temp_path, prompt_type="<MORE_DETAILED_CAPTION>")
                    
                    if user_q:
                        with st.spinner("ğŸ§  AI æ­£åœ¨æœé›†ç»†èŠ‚å¹¶æ€è€ƒ..."):
                            dense_data = vision_expert.analyze_image(temp_path, prompt_type="<DENSE_REGION_CAPTION>")
                            
                            # è§£æå¯†é›†æè¿°çš„æ•°æ® (å®ƒè¿”å›çš„æ˜¯å­—å…¸æˆ–è€…å­—ç¬¦ä¸²)
                            dense_text = ""
                            if isinstance(dense_data, dict) and 'labels' in dense_data:
                                # æå–æ‰€æœ‰æ ‡ç­¾å¹¶å»é‡
                                unique_labels = list(set(dense_data['labels']))
                                dense_text = ", ".join(unique_labels)
                            else:
                                dense_text = str(dense_data)

                            # === æ„å»ºè¶…çº§è¯¦ç»†çš„ä¸Šä¸‹æ–‡ ===
                            context = f"""
                            [å›¾ç‰‡å…¨å±€æè¿°]:
                            {st.session_state.img_description}
                            
                            [å›¾ç‰‡å±€éƒ¨ç»†èŠ‚/ç‰©ä½“æ ‡ç­¾]:
                            {dense_text}
                            """
                            
                            answer = llm_client.chat_with_context(user_q, context)
                            
                            st.markdown("### ğŸ¤– å›ç­”:")
                            st.success(answer)
                            
                            with st.expander("æŸ¥çœ‹ AI çœ‹åˆ°çš„å®Œæ•´è§†è§‰ä¿¡æ¯"):
                                st.text(context)
                        
    elif v_mode == "ä»¥æ–‡æœå›¾ (Image Search)":
        st.markdown("#### ğŸ” æœ¬åœ°å›¾ç‰‡åº“æœç´¢")
        
        # ç´¢å¼•æ„å»ºå·¥å…·
        with st.expander("âš™ï¸ ç´¢å¼•ç®¡ç† (å¦‚æœæœä¸åˆ°å›¾ï¼Œè¯·å…ˆç‚¹è¿™é‡Œ)"):
            img_dir = st.text_input("å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„:", value="./images")
            if st.button("ğŸ”„ é‡å»ºå›¾ç‰‡ç´¢å¼•"):
                count = 0
                image_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
                progress = st.progress(0)
                files = []
                for root, _, fs in os.walk(img_dir):
                    for f in fs:
                        if os.path.splitext(f)[1].lower() in image_exts:
                            files.append(os.path.join(root, f))
                
                for i, path in enumerate(files):
                    db_manager.add_image_embedding(path)
                    progress.progress((i+1)/len(files))
                    count += 1
                st.success(f"å·²ç´¢å¼• {count} å¼ å›¾ç‰‡ï¼")

        # æœç´¢ç•Œé¢
        search_q = st.text_input("æè¿°ä½ è¦æ‰¾çš„ç”»é¢:", placeholder="ä¸€åªåœ¨ç¡è§‰çš„çŒ«")
        if st.button("ğŸ–¼ï¸ æœç´¢å›¾ç‰‡"):
            if search_q:
                results = db_manager.search_images(search_q)
                if not results['ids'][0]:
                    st.warning("æœªæ‰¾åˆ°åŒ¹é…å›¾ç‰‡ã€‚")
                else:
                    cols = st.columns(3)
                    for i in range(len(results['ids'][0])):
                        img_path = results['ids'][0][i]
                        score = 1 - results['distances'][0][i]
                        if os.path.exists(img_path):
                            cols[i % 3].image(img_path, caption=f"åŒ¹é…åº¦: {score:.2f}")
                            cols[i % 3].caption(os.path.basename(img_path))