import argparse
import os
from tqdm import tqdm
from src.db_manager import DBManager
from src.llm_client import LLMClient
from src.vision_expert import VisionExpert
from src.file_handler import extract_text_from_pdf, move_file_to_category

def main():
    parser = argparse.ArgumentParser(description="Local Multimodal AI Agent (Ultimate Version)")
    subparsers = parser.add_subparsers(dest="command", help="Available commands")

    # Command: add_paper
    add_parser = subparsers.add_parser("add_paper", help="Add and classify papers with page-level indexing")
    add_parser.add_argument("path", help="Path to the PDF file or directory")
    add_parser.add_argument("--topics", required=True, help="Comma separated topics")

    # Command: search_paper (Advanced RAG)
    search_parser = subparsers.add_parser("search_paper", help="Semantic search & Q/A")
    search_parser.add_argument("query", help="Question about papers")

    # Command: scan_images
    scan_img_parser = subparsers.add_parser("scan_images", help="Index all images")
    scan_img_parser.add_argument("path", help="Directory path containing images")

    # Command: search_image
    img_parser = subparsers.add_parser("search_image", help="Search images by text")
    img_parser.add_argument("query", help="Text description")

    # Command: describe_image (Florence-2)
    desc_parser = subparsers.add_parser("describe_image", help="Generate detailed caption for an image")
    desc_parser.add_argument("path", help="Path to image file")

    # Command: ask_image (Florence-2)
    ask_parser = subparsers.add_parser("ask_image", help="Ask questions about an image")
    ask_parser.add_argument("path", help="Path to image file")
    ask_parser.add_argument("question", help="Your question")

    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return

    print("â³ æ­£åœ¨åˆå§‹åŒ– AI Agent (Loading All Models)...")
    db = DBManager()
    llm = LLMClient()
    # æ³¨æ„ï¼šé¦–æ¬¡è¿è¡Œä¼šåŠ è½½ Florence-2ï¼Œå¯èƒ½å ç”¨ 2-3GB æ˜¾å­˜
    vision_expert = VisionExpert()
    print("âœ… å…¨ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼\n")

    if args.command == "add_paper":
        files_to_process = []
        if os.path.isfile(args.path):
            files_to_process.append(args.path)
        elif os.path.isdir(args.path):
            for root, _, files in os.walk(args.path):
                for f in files:
                    if f.lower().endswith(".pdf"):
                        files_to_process.append(os.path.join(root, f))
        
        print(f"ğŸš€ å¼€å§‹å¤„ç† {len(files_to_process)} ä¸ªæ–‡ä»¶ (æŒ‰é¡µç´¢å¼•)...")
        
        for file_path in tqdm(files_to_process):
            chunks = extract_text_from_pdf(file_path)
            if not chunks:
                continue
            
            # ä½¿ç”¨ç¬¬ä¸€é¡µå†…å®¹è¿›è¡Œåˆ†ç±»
            first_page_text = chunks[0]['text']
            category = llm.classify_paper(first_page_text, args.topics)
            print(f"\nğŸ“„ æ–‡ä»¶: {os.path.basename(file_path)} -> ğŸ·ï¸ åˆ†ç±»: {category}")
            
            new_path = move_file_to_category(file_path, category)
            db.add_paper_chunks(new_path, chunks, category)

    elif args.command == "search_paper":
        print(f"ğŸ” æ­£åœ¨æ£€ç´¢å¹¶æ€è€ƒ: '{args.query}' ...")
        results = db.search_papers(args.query, n_results=3)
        
        if not results['ids'][0]:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚")
            return

        context_str = ""
        print("\nğŸ“š [æ£€ç´¢åˆ°çš„å‚è€ƒç‰‡æ®µ]:")
        for i in range(len(results['ids'][0])):
            meta = results['metadatas'][0][i]
            dist = results['distances'][0][i]
            text = results['documents'][0][i]
            
            context_str += f"--- æ–‡æ¡£: {meta['source']} (ç¬¬ {meta['page']} é¡µ) ---\n{text}\n\n"
            
            print(f"[{i+1}] {os.path.basename(meta['source'])}")
            print(f"    ğŸ“ é¡µç : Page {meta['page']} | åŒ¹é…åº¦: {1-dist:.4f}")
            print(f"    ğŸ“ ç‰‡æ®µ: \"{text[:100].replace(chr(10), ' ')}...\"\n")

        print("ğŸ¤– [AI æ™ºèƒ½å›ç­”]:")
        answer = llm.chat_with_context(args.query, context_str)
        print(f"{answer}\n")

    elif args.command == "scan_images":
        image_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.webp', '.tiff'}
        count = 0
        for root, _, files in os.walk(args.path):
            for f in files:
                if os.path.splitext(f)[1].lower() in image_exts:
                    path = os.path.join(root, f)
                    try:
                        if db.add_image_embedding(path):
                            print(f"âœ… ç´¢å¼•: {f}")
                            count += 1
                    except Exception:
                        pass
        print(f"\nğŸ‰ å·²ç´¢å¼• {count} å¼ å›¾ç‰‡ã€‚")

    elif args.command == "search_image":
        print(f"ğŸ–¼ï¸ æ­£åœ¨å¯»æ‰¾: '{args.query}'...")
        results = db.search_images(args.query)
        if not results['ids'][0]:
            print("æœªæ‰¾åˆ°ç›¸å…³å›¾ç‰‡ã€‚")
        else:
            for i in range(len(results['ids'][0])):
                doc_id = results['ids'][0][i]
                dist = results['distances'][0][i]
                print(f"[{i+1}] {doc_id} - åŒ¹é…åº¦: {1-dist:.4f}")

    elif args.command == "describe_image":
        print(f"ğŸ¨ æ­£åœ¨æ·±åº¦è§£æå›¾ç‰‡: {args.path} ...")
        result = vision_expert.analyze_image(args.path)
        print("\nğŸ“ [å›¾ç‰‡å†…å®¹æè¿°]:")
        print(result)

    elif args.command == "ask_image":
        print(f"â“ æ­£åœ¨å‘å›¾ç‰‡æé—®: '{args.question}' ...")
        result = vision_expert.analyze_image(args.path, user_question=args.question)
        print("\nğŸ¤– [å›ç­”]:")
        print(result)

if __name__ == "__main__":
    main()